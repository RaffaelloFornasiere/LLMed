events {
    multi_accept                    on;
    worker_connections              1024;
    use                             epoll;
}

http {
    server {
        listen 0.0.0.0:8080;

        location / {
            proxy_pass http://hbd_frontend:51118/;
        }

        location /api/ {
            proxy_pass http://hbd_backend:5003/;
            # Enable streaming for SSE
            proxy_buffering off;
            proxy_cache off;
            proxy_set_header Connection '';
            proxy_http_version 1.1;
            chunked_transfer_encoding off;
        }

        # llama-server proxy removed - now using Groq API via backend proxy
    }
}
